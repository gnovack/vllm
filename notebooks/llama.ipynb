{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/gnovack/vllm/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.models.llama.modeling_llama import apply_rotary_pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:MASTER_ADDR environment variable is not set, defaulting to localhost\n",
      "WARNING:root:Found libneuronpjrt.so. Setting PJRT_DEVICE=NEURON.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.model.layers = model.model.layers[:1]\n",
    "model = model.to(torch.bfloat16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([    1, 15043, 29892,   590,  1024,   338,     1,   450,  6673,   310,\n",
    "          278,  3303,  3900,   338,     1,   450,  7483,   310,  3444,   338,\n",
    "            1,   450,  5434,   310,   319, 29902,   338,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0],\n",
    "       dtype=torch.int32).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1494, -0.8125,  1.8359,  ..., -0.5195, -1.1484, -1.3516],\n",
       "        [-1.3359,  0.8125, -0.5938,  ...,  1.5391,  1.7188,  0.9023],\n",
       "        [-0.9570,  0.4316, -0.4121,  ...,  0.0747,  0.4453, -0.0378],\n",
       "        [ 0.9922, -1.5703,  1.7422,  ...,  0.3613,  0.2334,  1.2266],\n",
       "        [-0.0067,  1.4609,  0.8281,  ..., -1.0234,  0.9375,  0.7969],\n",
       "        [-1.1484,  1.3516, -0.0215,  ..., -0.5664, -0.6055,  3.0312]],\n",
       "       dtype=torch.bfloat16, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states[-1][0, :6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = logits.attentions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0031,  0.0178,  0.0210,  ..., -0.0052, -0.0420, -0.0334],\n",
       "         [ 0.0031,  0.0178,  0.0210,  ..., -0.0052, -0.0420, -0.0334],\n",
       "         [ 0.0031,  0.0178,  0.0210,  ..., -0.0052, -0.0420, -0.0334],\n",
       "         ...,\n",
       "         [ 0.0031,  0.0178,  0.0210,  ..., -0.0052, -0.0420, -0.0334],\n",
       "         [ 0.0031,  0.0178,  0.0210,  ..., -0.0052, -0.0420, -0.0334],\n",
       "         [ 0.0031,  0.0178,  0.0210,  ..., -0.0052, -0.0420, -0.0334]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = model.model.embed_tokens(input_ids)\n",
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0271,  0.1826,  0.3027,  ..., -0.0635, -0.4902, -0.2812],\n",
       "         [ 0.0271,  0.1826,  0.3027,  ..., -0.0635, -0.4902, -0.2812],\n",
       "         [ 0.0271,  0.1826,  0.3027,  ..., -0.0635, -0.4902, -0.2812],\n",
       "         ...,\n",
       "         [ 0.0271,  0.1826,  0.3027,  ..., -0.0635, -0.4902, -0.2812],\n",
       "         [ 0.0271,  0.1826,  0.3027,  ..., -0.0635, -0.4902, -0.2812],\n",
       "         [ 0.0271,  0.1826,  0.3027,  ..., -0.0635, -0.4902, -0.2812]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_shape = embeds.shape[:-1]\n",
    "# hidden_shape = (*input_shape, -1, 64)\n",
    "# k = model.model.layers[0].self_attn.k_proj(embeds)#.view(hidden_shape).transpose(1, 2)\n",
    "\n",
    "norm_embeds = model.model.layers[0].input_layernorm(embeds)\n",
    "norm_embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0148,  0.0123,  0.0157,  ...,  0.0266,  0.0075, -0.0199],\n",
      "         [-0.0148,  0.0123,  0.0157,  ...,  0.0266,  0.0075, -0.0199],\n",
      "         [-0.0148,  0.0123,  0.0157,  ...,  0.0266,  0.0075, -0.0199],\n",
      "         ...,\n",
      "         [-0.0148,  0.0123,  0.0157,  ...,  0.0266,  0.0075, -0.0199],\n",
      "         [-0.0148,  0.0123,  0.0157,  ...,  0.0266,  0.0075, -0.0199],\n",
      "         [-0.0148,  0.0123,  0.0157,  ...,  0.0266,  0.0075, -0.0199]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[-0.1001,  0.2559,  0.2871,  ...,  0.1953, -0.2969, -0.4707],\n",
      "         [-0.1001,  0.2559,  0.2871,  ...,  0.1953, -0.2969, -0.4707],\n",
      "         [-0.1001,  0.2559,  0.2871,  ...,  0.1953, -0.2969, -0.4707],\n",
      "         ...,\n",
      "         [-0.1001,  0.2559,  0.2871,  ...,  0.1953, -0.2969, -0.4707],\n",
      "         [-0.1001,  0.2559,  0.2871,  ...,  0.1953, -0.2969, -0.4707],\n",
      "         [-0.1001,  0.2559,  0.2871,  ...,  0.1953, -0.2969, -0.4707]]],\n",
      "       dtype=torch.bfloat16, grad_fn=<MulBackward0>)\n",
      "tensor([[[ 8.8501e-03, -1.6968e-02, -2.4902e-02,  ...,  3.2902e-05,\n",
      "          -2.0142e-02,  4.2419e-03],\n",
      "         [ 8.8501e-03, -1.6968e-02, -2.4902e-02,  ...,  3.2902e-05,\n",
      "          -2.0142e-02,  4.2419e-03],\n",
      "         [ 8.9111e-03, -1.7090e-02, -2.4902e-02,  ..., -8.9407e-06,\n",
      "          -2.0142e-02,  4.2419e-03],\n",
      "         ...,\n",
      "         [ 8.9722e-03, -1.7090e-02, -2.4780e-02,  ...,  1.4782e-05,\n",
      "          -2.0142e-02,  4.2419e-03],\n",
      "         [ 8.8501e-03, -1.6968e-02, -2.4902e-02,  ...,  3.2902e-05,\n",
      "          -2.0142e-02,  4.2419e-03],\n",
      "         [ 8.8501e-03, -1.6968e-02, -2.4902e-02,  ...,  3.2902e-05,\n",
      "          -2.0142e-02,  4.2419e-03]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_shape = embeds.shape[:-1]\n",
    "hidden_shape = (*input_shape, -1, 64)\n",
    "\n",
    "q = model.model.layers[0].self_attn.q_proj(norm_embeds)\n",
    "k = model.model.layers[0].self_attn.k_proj(norm_embeds)\n",
    "v = model.model.layers[0].self_attn.v_proj(norm_embeds)\n",
    "\n",
    "position_embeds = model.model.rotary_emb(embeds, torch.arange(0,128).unsqueeze(0))\n",
    "attn_out = model.model.layers[0].self_attn(norm_embeds, position_embeddings=position_embeds)\n",
    "print(attn_out[0])\n",
    "attn_out = attn_out[0] + embeds\n",
    "# print(attn_out)\n",
    "attn_out_norm = model.model.layers[0].post_attention_layernorm(attn_out)\n",
    "print(attn_out_norm)\n",
    "mlp_out = model.model.layers[0].mlp(attn_out_norm)\n",
    "print(mlp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          ...,\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275]],\n",
       "\n",
       "         [[-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          ...,\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275]],\n",
       "\n",
       "         [[-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          ...,\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          ...,\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275]],\n",
       "\n",
       "         [[-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          ...,\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275]],\n",
       "\n",
       "         [[-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          ...,\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275],\n",
       "          [-0.0038,  0.0505,  0.0369,  ...,  0.0034, -0.0287,  0.0275]]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(attn_scores, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8398,  2.2812,  2.7969,  ...,  5.7500,  0.9062, -3.4844],\n",
       "         [ 0.8398,  2.2812,  2.7969,  ...,  5.7500,  0.9062, -3.4844],\n",
       "         [ 0.8398,  2.2812,  2.7969,  ...,  5.7500,  0.9062, -3.4844],\n",
       "         ...,\n",
       "         [ 0.8398,  2.2812,  2.7969,  ...,  5.7500,  0.9062, -3.4844],\n",
       "         [ 0.8398,  2.2812,  2.7969,  ...,  5.7500,  0.9062, -3.4844],\n",
       "         [ 0.8398,  2.2812,  2.7969,  ...,  5.7500,  0.9062, -3.4844]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\n",
    "    'bsh,hq->bsq',\n",
    "    norm_embeds,\n",
    "    model.model.layers[0].self_attn.q_proj.weight.t()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2048) must match the size of tensor b (64) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrotary_emb(embeds, torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/gnovack/vllm/.venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:225\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    223\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    224\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m--> 225\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    226\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2048) must match the size of tensor b (64) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "\n",
    "apply_rotary_pos_emb(q, k, cos, sin)[0].transpose(1,2).reshape(1, 128, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
